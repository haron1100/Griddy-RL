{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from griddy_env import GriddyEnvOneHot\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_table_viz(value_table):\n",
    "    values = np.zeros((4, 4))\n",
    "    base_st = np.zeros((3, 4, 4), dtype=np.int64)\n",
    "    base_st[0, 3, 3]=1\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            test_st = deepcopy(base_st)\n",
    "            test_st[2, i, j] = 1\n",
    "            #print(test_st)\n",
    "            key = pickle.dumps(test_st)\n",
    "            if key in value_table:\n",
    "                val = value_table[key]\n",
    "            else:\n",
    "                val=0\n",
    "            values[i, j] = val\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_action(state):\n",
    "    action_values=[]\n",
    "    for test_action in range(4): #for each action\n",
    "        new_state = transition(state, test_action)\n",
    "        key = pickle.dumps(new_state)\n",
    "        if key not in value_table: value_table[key] = 0\n",
    "        action_values.append(value_table[key])\n",
    "    policy_action = np.argmax(action_values)\n",
    "    return policy_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Gs(episode_mem, discount_factor=0.95):\n",
    "    for i, mem in reversed(list(enumerate(episode_mem))):\n",
    "        if i==len(episode_mem)-1:\n",
    "            episode_mem[i]['G']= mem['reward']\n",
    "        else:\n",
    "            G = mem['reward']+discount_factor*episode_mem[i+1]['G']\n",
    "            episode_mem[i]['G'] = G   \n",
    "    return episode_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_value_table(value_table, episode_mem):\n",
    "    for mem in episode_mem:\n",
    "        key = pickle.dumps(mem['new_observation'])\n",
    "        if key not in value_table:\n",
    "            value_table[key]=0\n",
    "        #value_table[key] = max(value_table[key], mem['G'])\n",
    "        new_val = 0.9*value_table[key] + 0.1*mem['G']\n",
    "        diff = abs(value_table[key]\n",
    "        value_table[key] = newval\n",
    "    return value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(state, action):\n",
    "    state = deepcopy(state)\n",
    "    agent_pos = list(zip(*np.where(state[2] == 1)))[0]\n",
    "    new_agent_pos = np.array(agent_pos)\n",
    "    if action==0:\n",
    "        new_agent_pos[1]-=1\n",
    "    elif action==1:\n",
    "        new_agent_pos[1]+=1\n",
    "    elif action==2:\n",
    "        new_agent_pos[0]-=1\n",
    "    elif action==3:\n",
    "        new_agent_pos[0]+=1    \n",
    "    new_agent_pos = np.clip(new_agent_pos, 0, 3)\n",
    "\n",
    "    state[2, agent_pos[0], agent_pos[1]] = 0 #moved from this position so it is empty\n",
    "    state[2, new_agent_pos[0], new_agent_pos[1]] = 1 #moved to this position\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GriddyEnvOneHot()\n",
    "epsilon = 1\n",
    "value_table = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 7 timesteps. Eplislon=0.2900740880362934\n",
      "Episode finished after 5 timesteps. Eplislon=0.28891553096867023\n",
      "Episode finished after 7 timesteps. Eplislon=0.2871863657418441\n",
      "Episode finished after 9 timesteps. Eplislon=0.2848968999718006\n",
      "Episode finished after 5 timesteps. Eplislon=0.28375902061401054\n",
      "Episode finished after 3 timesteps. Eplislon=0.28319178633180314\n",
      "Episode finished after 7 timesteps. Eplislon=0.28149687783101773\n",
      "Episode finished after 8 timesteps. Eplislon=0.2795323012780908\n",
      "Episode finished after 13 timesteps. Eplislon=0.2761963014356792\n",
      "Episode finished after 5 timesteps. Eplislon=0.2750931723032361\n",
      "Episode finished after 5 timesteps. Eplislon=0.2739944490729594\n",
      "Episode finished after 4 timesteps. Eplislon=0.27317328743509334\n",
      "Episode finished after 2 timesteps. Eplislon=0.27290011414765825\n",
      "Episode finished after 5 timesteps. Eplislon=0.2718101500004249\n",
      "Episode finished after 3 timesteps. Eplislon=0.27126680151057403\n",
      "Episode finished after 5 timesteps. Eplislon=0.27018336082054484\n",
      "Episode finished after 4 timesteps. Eplislon=0.26937362101798235\n",
      "Episode finished after 6 timesteps. Eplislon=0.268029443956713\n",
      "Episode finished after 6 timesteps. Eplislon=0.2666919743524145\n",
      "Episode finished after 6 timesteps. Eplislon=0.26536117873480936\n",
      "Episode finished after 3 timesteps. Eplislon=0.26483072173851846\n",
      "Episode finished after 8 timesteps. Eplislon=0.2629824588716937\n",
      "Episode finished after 7 timesteps. Eplislon=0.2614085035996406\n",
      "Episode finished after 6 timesteps. Eplislon=0.2601040725539001\n",
      "Episode finished after 5 timesteps. Eplislon=0.25906521584796366\n",
      "Episode finished after 2 timesteps. Eplislon=0.2588061506321157\n",
      "Episode finished after 7 timesteps. Eplislon=0.25725719064833996\n",
      "Episode finished after 6 timesteps. Eplislon=0.25597347469571885\n",
      "Episode finished after 8 timesteps. Eplislon=0.25418702686569955\n",
      "Episode finished after 9 timesteps. Eplislon=0.2521606336708316\n",
      "Episode finished after 3 timesteps. Eplislon=0.25165656456412355\n",
      "Episode finished after 7 timesteps. Eplislon=0.2501503949958493\n",
      "Episode finished after 7 timesteps. Eplislon=0.248653239882542\n",
      "Episode finished after 5 timesteps. Eplislon=0.24766011784808684\n",
      "Episode finished after 10 timesteps. Eplislon=0.2454400717794207\n",
      "Episode finished after 7 timesteps. Eplislon=0.24397110804469957\n",
      "Episode finished after 8 timesteps. Eplislon=0.24226842515120073\n",
      "Episode finished after 3 timesteps. Eplislon=0.24178413056932346\n",
      "Episode finished after 4 timesteps. Eplislon=0.24105950328822306\n",
      "Episode finished after 7 timesteps. Eplislon=0.2396167573434674\n",
      "Episode finished after 4 timesteps. Eplislon=0.2388986256820923\n",
      "Episode finished after 7 timesteps. Eplislon=0.2374688126329945\n",
      "Episode finished after 3 timesteps. Eplislon=0.23699411247654112\n",
      "Episode finished after 6 timesteps. Eplislon=0.2358115094865268\n",
      "Episode finished after 8 timesteps. Eplislon=0.2341657727166659\n",
      "Episode finished after 7 timesteps. Eplislon=0.23276428588715223\n",
      "Episode finished after 7 timesteps. Eplislon=0.23137118698432196\n",
      "Episode finished after 6 timesteps. Eplislon=0.23021664244871493\n",
      "Episode finished after 14 timesteps. Eplislon=0.22724171731734197\n",
      "Episode finished after 5 timesteps. Eplislon=0.22633411298963688\n",
      "Episode finished after 3 timesteps. Eplislon=0.22588167109777058\n",
      "Episode finished after 2 timesteps. Eplislon=0.2256557894266728\n",
      "Episode finished after 2 timesteps. Eplislon=0.22543013363724612\n",
      "Episode finished after 8 timesteps. Eplislon=0.2238568488524224\n",
      "Episode finished after 9 timesteps. Eplislon=0.22207224953304477\n",
      "Episode finished after 6 timesteps. Eplislon=0.2209641067882625\n",
      "Episode finished after 4 timesteps. Eplislon=0.22030187713925398\n",
      "Episode finished after 10 timesteps. Eplislon=0.21832707263495027\n",
      "Episode finished after 5 timesteps. Eplislon=0.2174550734337563\n",
      "Episode finished after 5 timesteps. Eplislon=0.21658655700085905\n",
      "Episode finished after 2 timesteps. Eplislon=0.2163699704438582\n",
      "Episode finished after 3 timesteps. Eplislon=0.21593744687294092\n",
      "Episode finished after 6 timesteps. Eplislon=0.21485991685474995\n",
      "Episode finished after 5 timesteps. Eplislon=0.21400176548760727\n",
      "Episode finished after 9 timesteps. Eplislon=0.21229573144400934\n",
      "Episode finished after 5 timesteps. Eplislon=0.21144782144365132\n",
      "Episode finished after 5 timesteps. Eplislon=0.21060329799922556\n",
      "Episode finished after 5 timesteps. Eplislon=0.20976214758481407\n",
      "Episode finished after 8 timesteps. Eplislon=0.20829821022248174\n",
      "Episode finished after 2 timesteps. Eplislon=0.20808991201225926\n",
      "Episode finished after 6 timesteps. Eplislon=0.20705154127145922\n",
      "Episode finished after 7 timesteps. Eplislon=0.20581233365902327\n",
      "Episode finished after 5 timesteps. Eplislon=0.20499031837534562\n",
      "Episode finished after 4 timesteps. Eplislon=0.20437596218618437\n",
      "Episode finished after 9 timesteps. Eplislon=0.20274666558487714\n",
      "Episode finished after 6 timesteps. Eplislon=0.20173495769715546\n",
      "Episode finished after 10 timesteps. Eplislon=0.19992658861601492\n",
      "Episode finished after 7 timesteps. Eplislon=0.19873002398761402\n",
      "Episode finished after 5 timesteps. Eplislon=0.1979362954770861\n",
      "Episode finished after 6 timesteps. Eplislon=0.19694859138428197\n",
      "Episode finished after 5 timesteps. Eplislon=0.19616197792269574\n",
      "Episode finished after 6 timesteps. Eplislon=0.19518312769222232\n",
      "Episode finished after 4 timesteps. Eplislon=0.1945981636633456\n",
      "Episode finished after 3 timesteps. Eplislon=0.19420916193418256\n",
      "Episode finished after 2 timesteps. Eplislon=0.19401495277224837\n",
      "Episode finished after 6 timesteps. Eplislon=0.1930468162187352\n",
      "Episode finished after 5 timesteps. Eplislon=0.1922757864627634\n",
      "Episode finished after 2 timesteps. Eplislon=0.1920835106763006\n",
      "Episode finished after 9 timesteps. Eplislon=0.1905522101859476\n",
      "Episode finished after 2 timesteps. Eplislon=0.19036165797576166\n",
      "Episode finished after 2 timesteps. Eplislon=0.1901712963177859\n",
      "Episode finished after 2 timesteps. Eplislon=0.1899811250214681\n",
      "Episode finished after 7 timesteps. Eplislon=0.18884408419144066\n",
      "Episode finished after 5 timesteps. Eplislon=0.18808984016399252\n",
      "Episode finished after 6 timesteps. Eplislon=0.18715126998161608\n",
      "Episode finished after 7 timesteps. Eplislon=0.18603116589055688\n",
      "Episode finished after 4 timesteps. Eplislon=0.18547363030035172\n",
      "Episode finished after 9 timesteps. Eplislon=0.18399502414604677\n",
      "Episode finished after 8 timesteps. Eplislon=0.1827109164391416\n",
      "Episode finished after 7 timesteps. Eplislon=0.18161738795277457\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i_episode in range(100):\n",
    "        old_observation = env.reset()\n",
    "        done=False\n",
    "        episode_mem = []\n",
    "        t=0\n",
    "        while not done:\n",
    "            env.render()\n",
    "            \n",
    "            policy_action = pick_best_action(old_observation)\n",
    "            action = env.action_space.sample() if np.random.rand()<epsilon else policy_action\n",
    "            #action = env.action_space.sample()\n",
    "            #print(action)\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            episode_mem.append({'old_observation':deepcopy(old_observation),\n",
    "                                'action':action,\n",
    "                                'reward':reward,\n",
    "                                'new_observation':deepcopy(new_observation),\n",
    "                                'done':done})\n",
    "            old_observation=deepcopy(new_observation)\n",
    "            t+=1\n",
    "            epsilon*=0.999\n",
    "            #time.sleep(0.5)\n",
    "        print(\"Episode finished after {} timesteps. Eplislon={}\".format(t+1, epsilon))\n",
    "        env.render()\n",
    "        #time.sleep(0.5)\n",
    "        episode_mem = calculate_Gs(episode_mem)\n",
    "        value_table = update_value_table(value_table, episode_mem)\n",
    "    env.close()\n",
    "except KeyboardInterrupt:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3060108 , 0.52833382, 0.64338609, 0.66168489],\n",
       "       [0.33759043, 0.43687646, 0.78736672, 0.81200628],\n",
       "       [0.66962984, 0.7985848 , 0.86683305, 0.9336722 ],\n",
       "       [0.3415757 , 0.46164763, 0.7553073 , 0.99997344]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_table_viz(value_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
